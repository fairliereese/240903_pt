
import pandas as pd
import os
import sys
import pyranges as pr

p = os.path.dirname(os.path.dirname(os.getcwd()))+'/scripts/'
sys.path.append(p)

from sm_utils import *
from utils import *
# from vcf_utils import *

c_dir = '../common/'

meta_file = '../config.tsv'
configfile: '../config.yml'

include: f'{c_dir}download.smk'
include: f'{c_dir}samtools.smk'
include: f'{c_dir}winnowmap.smk'
include: f'{c_dir}bigwig.smk'
include: f'{c_dir}variant_calling.smk'
include: f'{c_dir}formatting.smk'
include: f'{c_dir}phasing.smk'
include: f'{c_dir}cerberus.smk'
include: f'{c_dir}bedtools.smk'
include: f'{c_dir}transdecoder.smk'
include: f'{c_dir}protein.smk'
include: f'{c_dir}minimap2.smk'
include: f'{c_dir}stats.smk'
include: f'{c_dir}lr-kallisto.smk'
include: f'{c_dir}kallisto.smk'
include: f'{c_dir}suppa.smk'

# sample information
meta_file = '../config.tsv'

df = load_meta()
df = df.loc[~df['sample'].str.contains('_')]
df['lab_sample'] = df['lab_number_sample'].astype(str)+'_'+\
                      df['lab_sampleid'].astype(str)+'_'+\
                      df['cell_line_id'].astype(str)
df = df.loc[df.mixed_samples==False]
df = df[['cell_line_id', 'sample', 'hapmap_DNA_ID', 'lab_sample']].drop_duplicates()


hprc_df = pd.read_csv('kinnex_metadata_2.tsv', sep='\t')



def get_df_val(df, col1, col_dict):
    temp = df.copy(deep=True)

    for key, item in col_dict.items():
        temp = temp.loc[temp[key] == item]

    val = temp[col1].unique()
    assert len(val) == 1
    return val[0]

wildcard_constraints:
    sample_rep='|'.join(hprc_df['sample_rep'].unique()),
    sample_id='|'.join(hprc_df['sample_id'].unique()),
    sample='|'.join(df['sample'].unique())


rule all:
    input:
        config['lr']['tss_pls_int_count_summary'],
        config['hprc']['kinnex']['map']['tss_pls_int_count_summary']
        # expand(config['lr']['tss_pls_int_count'],
        #        sample=df['sample'].tolist()),
        # expand(config['hprc']['kinnex']['map']['tss_pls_int_count'],
        #        sample_id=hprc_df.sample_id.tolist())

# first reorient all reads
use rule flip_reads as captrap_flip_reads with:
    input:
        bam = lambda wc: expand(config['lr']['q10_bam'],
               lab_sample=get_df_val(df, 'lab_sample', {'sample': wc.sample}))[0]
    output:
        bam = config['lr']['q10_flip_bam']

use rule flip_reads as hprc_flip_reads with:
    input:
        bam = config['hprc']['kinnex']['map']['q10_bam']
    output:
        bam = config['hprc']['kinnex']['map']['q10_flip_bam']

use rule oriented_bam_to_tss_bed as captrap_bam_to_tss_bed with:
    input:
        bam = config['lr']['q10_flip_bam']
    output:
        bed = config['lr']['q10_tss_bed']

use rule oriented_bam_to_tss_bed as hprc_bam_to_tss_bed with:
    input:
        bam = config['hprc']['kinnex']['map']['q10_flip_bam']
    output:
        bed = config['hprc']['kinnex']['map']['q10_tss_bed']

rule pls_ccre_int:
    resources:
        threads = 8,
        nodes = 1
    shell:
        """
        module load bedtools
        bedtools intersect -loj \
                           -wa \
                           -a {input.bed} \
                           -b {input.pls} > \
                           {output.tsv}
        """

use rule pls_ccre_int as captrap_pls_ccre_int with:
    input:
        pls = config['ref']['ccre']['pls_bed'],
        bed = config['lr']['q10_tss_bed']
    output:
        tsv = temporary(config['lr']['tss_pls_int'])

use rule pls_ccre_int as hprc_pls_ccre_int with:
    input:
        pls = config['ref']['ccre']['pls_bed'],
        bed = config['hprc']['kinnex']['map']['q10_tss_bed']
    output:
        tsv = temporary(config['hprc']['kinnex']['map']['tss_pls_int'])


rule count_pls_int_reads:
    resources:
        threads = 1,
        nodes = 2
    run:
        df = pd.read_csv(input.tsv, sep='\t', header=None)
        df = df[[3, 7, 9]]
        df.columns = ['read_name', 'intersect', 'pls_id']

        # assumptions about intersection formatting
        # from bedtools are OK
        assert len(df.loc[(df.intersect==-1)&(df.pls_id!='.')].index) == 0

        # # only reporting one per read
        # assert len(df.read_name.unique()) == len(df.index)

        df['int_pls'] = df.pls_id!='.'
        df = df[['read_name', 'int_pls']].groupby('int_pls').nunique().reset_index()

        df.rename({'read_name':'n_reads'}, axis=1, inplace=True)
        df['n_total_reads'] = df.n_reads.sum(axis=0)
        df['perc_reads'] = (df['n_reads']/df['n_total_reads'])*100

        df.to_csv(output.tsv, sep='\t')

use rule count_pls_int_reads as hprc_count_pls_int_reads with:
    input:
        tsv = config['hprc']['kinnex']['map']['tss_pls_int']
    output:
        tsv = config['hprc']['kinnex']['map']['tss_pls_int_count']
use rule count_pls_int_reads as captrap_count_pls_int_reads with:
    input:
        tsv = config['lr']['tss_pls_int']
    output:
        tsv = config['lr']['tss_pls_int_count']

use rule df_summary as hprc_get_pls_int_summary with:
    input:
        tsvs = lambda wc: expand(config['hprc']['kinnex']['map']['tss_pls_int_count'],
                                 sample_id=hprc_df.sample_id.tolist()),
    params:
        samples = hprc_df.sample_id.tolist(),
        col = 'sample'
    output:
        summ = config['hprc']['kinnex']['map']['tss_pls_int_count_summary']
use rule df_summary as captrap_get_pls_int_summary with:
    input:
        tsvs = lambda wc: expand(config['lr']['tss_pls_int_count'],
                          sample=df['sample'].tolist())
    params:
        samples = df['sample'].tolist(),
        col = 'sample'
    output:
        summ = config['lr']['tss_pls_int_count_summary']
