import pandas as pd
import os
import sys

p = os.path.dirname(os.path.dirname(os.getcwd()))+'/scripts/'
sys.path.append(p)

from sm_utils import *
from utils import *
# from vcf_utils import *

c_dir = '../common/'

meta_file = '../config.tsv'
meta_file_2 = 'config.tsv'
genomes_file = 'genomes_config.tsv'
configfile: '../config.yml'

include: f'{c_dir}download.smk'
include: f'{c_dir}samtools.smk'
include: f'{c_dir}winnowmap.smk'
include: f'{c_dir}bigwig.smk'
include: f'{c_dir}variant_calling.smk'
include: f'{c_dir}formatting.smk'
include: f'{c_dir}phasing.smk'
include: f'{c_dir}cerberus.smk'
include: f'{c_dir}bedtools.smk'
include: f'{c_dir}transdecoder.smk'
include: f'{c_dir}protein.smk'
include: f'{c_dir}minimap2.smk'
include: f'{c_dir}stats.smk'


meta_file = '../config.tsv'
meta_file_2 = 'config.tsv'
genomes_file = 'genomes_config.tsv'

df = parse_config(meta_file)
df2 = pd.read_csv(meta_file_2, sep='\t')
df2['tech_rep'] = df2.cell_line_id+'_1'
df2['same_sample'] = df2['pangenome_code']

# TODO test
# df2 = df2.loc[df2.cell_line_id == 'GM24385']

# get the genomes to download
g_df = pd.read_csv(genomes_file, sep='\t')

# maternal haplotypes
g_df['aws_mat_link'] = g_df['hap2_aws_fasta']
g_df = g_df.loc[g_df['aws_mat_link'].notnull()]
assert len(g_df.loc[g_df['aws_mat_link'].str.contains('maternal')].index) == len(g_df.index)

# paternal haplotypes
g_df['aws_pat_link'] = g_df['hap1_aws_fasta']
g_df = g_df.loc[g_df['aws_pat_link'].notnull()]
assert len(g_df.loc[g_df['aws_pat_link'].str.contains('paternal')].index) == len(g_df.index)

genome_cols = ['same_population_sample', 'european_sample',	'afr_sample', 'same_sample']
assemblies = genome_cols
# g_df = g_df.loc[(g_df['sample'].isin(df2[genome_cols[0]]))|
#                 (g_df['sample'].isin(df2[genome_cols[1]]))|
#                 (g_df['sample'].isin(df2[genome_cols[2]]))|
#                 (g_df['sample'].isin(df2[genome_cols[3]]))]

# a little more df2 formatting
df2 = df2[['tech_rep']+assemblies].melt(id_vars='tech_rep')
df2 = df2.reset_index()
df2 = df2.rename({'variable':'assembly_status',
                  'value': 'assembly_sample'},
                  axis=1)

# # limit just to the samples where we'll do this
# df = df.loc[df.tech_rep.isin(df2.tech_rep.tolist())]

# get a key for assembly status, assembly sample, and actual sample
df2['dataset_key'] = df2.assembly_status+'_'+\
                     df2.assembly_sample+'_'+\
                     df2.tech_rep

g_df = g_df[['sample', 'aws_mat_link', 'aws_pat_link']]
g_df = g_df = pd.melt(g_df, id_vars=['sample'],
                  value_vars=['aws_mat_link', 'aws_pat_link'],
                  var_name='haplotype', value_name='link')

# Map 'haplotype' column to 'maternal' or 'paternal' based on the column name
g_df['haplotype'] = g_df['haplotype'].map({
    'aws_mat_link': 'maternal',
    'aws_pat_link': 'paternal'
})

wildcard_constraints:
    assembly_sample='|'.join([re.escape(x) for x in g_df['sample'].tolist()]),,
    assembly_haplotype='|'.join([re.escape(x) for x in g_df['haplotype'].tolist()]),,
    sample='|'.join([re.escape(x) for x in df.tech_rep.tolist()]),
    lab_rep='|'.join([re.escape(x) for x in df.lab_rep.tolist()]),

rule all:
    input:
        expand(config['lr']['personal_kallisto']['quant']['merge_matrix_tpm_tsv'],
               assembly_sample=g_df['sample'].tolist(),
               assembly_haplotype=g_df['haplotype'].tolist()),
        expand(config['lr']['personal_kallisto']['quant']['merge_matrix_tsv'],
               assembly_sample=g_df['sample'].tolist(),
               assembly_haplotype=g_df['haplotype'].tolist()),
        # expand(config['ref']['alt']['personal']['fa_gz'],
        #        assembly_sample=g_df['sample'].tolist(),
        #        assembly_haplotype=g_df['haplotype'].tolist())


def get_df_val(df, col1, col_dict, uniq_val=True):
    """
    uniq_val (b0ool) needs to return a uniq val rather
        than a list
    """
    temp = df.copy(deep=True)

    for key, item in col_dict.items():
        temp = temp.loc[temp[key] == item]

    if uniq_val:
        val = temp[col1].unique()
        assert len(val) == 1
        return val[0]
    else:
        return temp[col1].tolist()

use rule dl_aws as dl_personal_assembly_mat with:
    params:
        link = lambda wc: get_df_val(g_df, 'link',
                            {'sample': wc.assembly_sample,
                             'haplotype': wc.assembly_haplotype})
    output:
        out = config['ref']['alt']['personal']['fa_gz']
#
# use rule dl_aws as dl_personal_assembly_pat with:
#     params:
#         link = lambda wc: get_df_val(g_df, 'aws_pat_link',
#                             {'sample': wc.assembly_sample})
#     output:
#         out = config['ref']['alt']['personal']['pat_fa_gz']


use rule kallisto_build_ind as kallisto_ind with:
    input:
        fa = config['ref']['alt']['personal']['fa_gz'],
        # gtf = config['lr']['gtf_filt_with_genes'] # TODO fabiens GTF
    output:
        ind = config['ref']['personal']['kallisto']['ind'],
        fa = config['ref']['personal']['kallisto']['t_fa'],
        t2g = config['ref']['personal']['kallisto']['t2g'],


use rule kallisto_pseudoalign as pseudoalign with:
    input:
        ind = config['ref']['personal']['kallisto']['ind'],
        fq = lambda wc: expand(config['lr']['fastq'],
                    lab_sample=get_df_val(df,
                            'lab_rep',
                            {'tech_rep': wc.sample})),
    params:
        kallisto_path = '/gpfs/home/bsc/bsc083001/miniconda3/envs/lr-kallisto/bin/kallisto',
        odir = config['lr']['personal_kallisto']['odir']
    output:
        bus = config['lr']['personal_kallisto']['bus'],
        flens = config['lr']['personal_kallisto']['flens'],
        transcripts = config['lr']['personal_kallisto']['transcripts'],
        matrix = config['lr']['personal_kallisto']['matrix']

use rule bustools_sort as bt_sort with:
    input:
        bus = config['lr']['personal_kallisto']['bus']
    output:
        bus = config['lr']['personal_kallisto']['bus_sort']

use rule bustools_count as bt_count with:
    input:
        bus = config['lr']['personal_kallisto']['bus_sort'],
        transcripts = config['lr']['personal_kallisto']['transcripts'],
        matrix = config['lr']['personal_kallisto']['matrix'],
        t2g = config['ref']['personal']['kallisto']['t2g']
    params:
        bustools_path = '/gpfs/home/bsc/bsc083001/miniconda3/envs/bustools/bin/bustools',
        count_pref = config['lr']['personal_kallisto']['count_pref']
    output:
        mtx = config['lr']['personal_kallisto']['count_mtx'],
        ec = config['lr']['personal_kallisto']['count_ec']

use rule lr_kallisto as run_lr_kallisto with:
    input:
        flens = config['lr']['personal_kallisto']['flens'],
        mtx = config['lr']['personal_kallisto']['count_mtx'],
        ind = config['ref']['personal']['kallisto']['ind'],
        ec = config['lr']['personal_kallisto']['count_ec']
    params:
        kallisto_path = '/gpfs/home/bsc/bsc083001/miniconda3/envs/lr-kallisto/bin/kallisto',
        odir = config['lr']['personal_kallisto']['quant']['odir']
    output:
        quant = config['lr']['personal_kallisto']['quant']['matrix'],
        tpm = config['lr']['personal_kallisto']['quant']['matrix_tpm'],

use rule fmt_mtx_transcripts as get_counts_mtx with:
    input:
        mtx = config['lr']['personal_kallisto']['quant']['matrix'],
        ts = config['lr']['personal_kallisto']['transcripts']
    params:
        col = 'counts'
    output:
        tsv = config['lr']['personal_kallisto']['quant']['matrix_tsv']

use rule fmt_mtx_transcripts as get_tpm_mtx with:
    input:
        mtx = config['lr']['personal_kallisto']['quant']['matrix_tpm'],
        ts = config['lr']['personal_kallisto']['transcripts']
    params:
        col = 'counts'
    output:
        tsv = config['lr']['personal_kallisto']['quant']['matrix_tpm_tsv']

rule merge_matrices:
    resources:
        nodes = 3,
        threads = 1
    run:
        merge_df = pd.DataFrame()
        samples = list(params.samples)
        i = 0
        for t, s in zip(list(input.tsvs), samples):
            temp = pd.read_csv(t, sep='\t')
            temp.rename({'counts': s}, axis=1, inplace=True)
            if i == 0:
                merge_df = temp.copy(deep=True)
            else:
                merge_df = merge_df.merge(temp, how='outer',
                            on='transcript_id')
            i+=1
        merge_df.to_csv(output.tsv, sep='\t', index=False)

use rule merge_matrices as merge_matrices_tpm with:
    input:
        tsvs = expand(config['lr']['personal_kallisto']['quant']['matrix_tpm_tsv'],
                      sample=df.tech_rep.tolist())
    params:
        samples = df.tech_rep.tolist()
    output:
        tsv = config['lr']['personal_kallisto']['quant']['merge_matrix_tpm_tsv']

use rule merge_matrices as merge_matrices_counts with:
    input:
        tsvs = expand(config['lr']['personal_kallisto']['quant']['matrix_tsv'],
                      sample=df.tech_rep.tolist())
    params:
        samples = df.tech_rep.tolist()
    output:
        tsv = config['lr']['personal_kallisto']['quant']['merge_matrix_tsv']
