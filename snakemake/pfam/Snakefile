import pandas as pd
import os
import sys

p = os.path.dirname(os.path.dirname(os.getcwd()))+'/scripts/'
sys.path.append(p)

from sm_utils import *
from utils import *

c_dir = '../common/'

meta_file = '../config.tsv'
configfile: '../config.yml'

df = parse_config(meta_file)

wildcard_constraints:
    sample='|'.join([re.escape(x) for x in df.tech_rep.tolist()]),
    lab_rep='|'.join([re.escape(x) for x in df.lab_rep.tolist()]),


include: f'{c_dir}download.smk'
include: f'{c_dir}samtools.smk'
include: f'{c_dir}winnowmap.smk'
include: f'{c_dir}bigwig.smk'
include: f'{c_dir}variant_calling.smk'
include: f'{c_dir}formatting.smk'
include: f'{c_dir}phasing.smk'
include: f'{c_dir}cerberus.smk'
include: f'{c_dir}lr-kallisto.smk'

# df = df.loc[df.tech_rep=='GM19240_1']

# import pdb; pdb.set_trace()

rule all:
    input:
        config['ref']['pfam']['hmmer_out_align'],
        config['lr']['pfam']['hmmer_out_align']
        # config['ref']['pfam']['db']
        # config['lr']['pfam']['pc_fa']

# ##### reference dl
# use rule wget as wget_pfam_db with:
#     params:
#         link = config['ref']['pfam']['link']
#     output:
#         out = temporary(config['ref']['pfam']['db_gz'])
#
# use rule gunzip as gunzip_pfam_db with:
#     input:
#         gz = config['ref']['pfam']['db_gz']
#     output:
#         ofile = config['ref']['pfam']['db']

#### prepare transcript fas
rule filt_prot_table:
    input:
        gtf = config['lr']['nov_gtf_filt_with_genes'],
        tsv = config['lr']['protein']['summary']
    resources:
        threads = 1,
        nodes = 2
    output:
        tsv = config['lr']['protein']['summary_filt']
    run:
        import pyranges as pr
        df = pr.read_gtf(input.gtf).df
        tids = df.transcript_id.unique().tolist()
        df = pd.read_csv(input.tsv, sep='\t')
        l1 = len(df.index)
        df = df.loc[df.tid.isin(tids)]
        l2 = len(df.index)
        assert l1 != l2
        df.to_csv(output.tsv, sep='\t', index=False)

rule prot_table_to_prot_fa:
    input:
        tsv = config['lr']['protein']['summary_filt']
    resources:
        threads =  1,
        nodes = 2
    output:
        fa = config['lr']['pfam']['pc_fa']
    run:
        df = pd.read_csv(input.tsv, sep='\t')
        df = df[['tid', 'protein_sequence']]
        with open(output.fa, 'w') as out:
            for ind, entry in df.iterrows():
                out.write(f'>{entry.tid}\n')
                out.write(f'{entry.protein_sequence}\n')

rule run_hmmer:
    resources:
        threads = 8,
        nodes = 4
    shell:
        """
        {params.hmmer_path}hmmscan \
            --domtblout {output.txt} \
    		-E {params.eval} \
    		--cpu {resources.threads} \
    		{input.db} \
    		{input.fa} > {output.txt_align}
        """

use rule run_hmmer as run_hmmer_poder with:
    input:
        fa = config['lr']['pfam']['pc_fa'],
        db = config['ref']['pfam']['db']
    params:
        eval = config['params']['hmmer']['eval']
    output:
        txt = config['lr']['pfam']['hmmer_out'],
        txt_align = config['lr']['pfam']['hmmer_out_align']

use rule run_hmmer as run_hmmer_gc with:
    input:
        fa = config['ref']['pc_renamed'],
        db = config['ref']['pfam']['db']
    params:
        eval = config['params']['hmmer']['eval']
    output:
        txt = config['ref']['pfam']['hmmer_out'],
        txt_align = config['ref']['pfam']['hmmer_out_align']
