import pandas as pd
import os
import sys

p = os.path.dirname(os.path.dirname(os.getcwd()))+'/scripts/'
sys.path.append(p)

from sm_utils import *
from utils import *
# from vcf_utils import *

c_dir = '../common/'

meta_file = '../config.tsv'
meta_file_2 = 'config.tsv'
genomes_file = 'genomes_config.tsv'
configfile: '../config.yml'

include: f'{c_dir}download.smk'
include: f'{c_dir}samtools.smk'
include: f'{c_dir}winnowmap.smk'
include: f'{c_dir}bigwig.smk'
include: f'{c_dir}variant_calling.smk'
include: f'{c_dir}formatting.smk'
include: f'{c_dir}phasing.smk'
include: f'{c_dir}cerberus.smk'
include: f'{c_dir}bedtools.smk'
include: f'{c_dir}transdecoder.smk'
include: f'{c_dir}protein.smk'
include: f'{c_dir}minimap2.smk'
include: f'{c_dir}stats.smk'

df = pd.read_csv('data_kinnex_pre_release.index.csv', sep=',')
df['sample_rep'] = df['sample_id']+'_'+(df.sort_values(by=['sample_id']).groupby(['sample_id']).cumcount()+1).astype(str)

def get_df_val(df, col1, col_dict):
    temp = df.copy(deep=True)

    for key, item in col_dict.items():
        temp = temp.loc[temp[key] == item]

    val = temp[col1].unique()
    assert len(val) == 1
    return val[0]


wildcard_constraints:
    sample_rep='|'.join(df['sample_rep'].unique()),
    sample='|'.join(df['sample_id'].unique())

rule all:
    input:
        config['hprc']['kinnex']['map']['bam_n_reads_summary'],
        config['hprc']['kinnex']['flnc_bam_n_reads_summary']
        # expand(config['hprc']['kinnex']['flnc_bam'],
        #        sample_rep=df.sample_rep.tolist())

use rule dl_aws as dl_hprc_kinnex with:
    params:
        link = lambda wc: get_df_val(df, 'path',
                                     {'sample_rep':wc.sample_rep})
    output:
        out = config['hprc']['kinnex']['flnc_bam']

### index genome
use rule minimap2_index as ind_alt_assembly with:
    input:
        fa = config['ref']['fa']
    output:
        ind = config['ref']['fa_mmi']

use rule minimap2_with_index_pacbio as hprc_map with:
    input:
        bam = config['hprc']['kinnex']['flnc_bam'],
        ind = config['ref']['fa_mmi']
    resources:
        threads = 8,
        nodes = 2
    output:
        sam = temporary(config['hprc']['kinnex']['map']['sam'])

use rule filt_non_prim_unmap_supp as hprc_filt_map with:
    input:
        align = config['hprc']['kinnex']['map']['sam']
    output:
        align = temporary(config['hprc']['kinnex']['map']['sam_filt'])

use rule sam_to_bam as hprc_sam_to_bam with:
    input:
        sam = config['hprc']['kinnex']['map']['sam_filt']
    output:
        bam = temporary(config['hprc']['kinnex']['map']['bam'])

# index and sort bam
use rule sort_bam as hprc_sort_bam with:
    input:
        bam = config['hprc']['kinnex']['map']['bam']
    output:
        bam = config['hprc']['kinnex']['map']['bam_sort']

use rule index_bam as hprc_index_bam with:
    input:
        bam = config['hprc']['kinnex']['map']['bam_sort']
    output:
        ind = config['hprc']['kinnex']['map']['bam_ind']
#
# # ### statistics
# # rule all_stats:
# #     input:
# #         config['lr']['fastq_n_reads_summary'],
# #         expand(config['hprc']['kinnex']['map']['bam_n_reads_summary'],
# #                assembly=assemblies),
# #         expand(config['hprc']['kinnex']['map']['bam_mapqs_summary'],
# #               assembly=assemblies)
# #
# #

# raw flnc bam counts
use rule count_bam as hprc_count_raw_reads with:
    input:
        bam = config['hprc']['kinnex']['flnc_bam']
    output:
        txt = temporary(config['hprc']['kinnex']['flnc_bam_n_reads'])

use rule count_reads_summary as hprc_count_reads_summary with:
    input:
        txts = lambda wc: expand(config['hprc']['kinnex']['flnc_bam_n_reads'],
                                sample_rep=df['sample_rep'].tolist()),
    params:
        samples = df['sample_rep'].tolist()
    output:
        summ = config['hprc']['kinnex']['flnc_bam_n_reads_summary']

# filtered bam counts
use rule count_bam as hprc_count_mapped_reads with:
    input:
        align = config['hprc']['kinnex']['map']['bam_sort']
    output:
        txt = config['hprc']['kinnex']['map']['bam_n_reads']

use rule count_reads_summary as sam_count_reads_summary with:
    input:
        txts = lambda wc: expand(config['hprc']['kinnex']['map']['bam_n_reads'],
                                sample_rep=df['sample_rep'].tolist()),
    params:
        samples = df['sample_rep'].tolist()
    output:
        summ = config['hprc']['kinnex']['map']['bam_n_reads_summary']
