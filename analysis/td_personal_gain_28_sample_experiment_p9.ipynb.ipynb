{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cceba34d-cb3f-4e5d-b40b-084b89772940",
   "metadata": {},
   "source": [
    "## Goal: If we have 28 samples and have to choose to \n",
    "\n",
    "- 1. do lr rna-seq for 2 samples (only use GRCh38) or\n",
    "- 2. do lr-rna-seq for 1 sample w/ personalized GRCh38 transcript discovery, what's best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0177d45-5561-41d1-9dc7-c7ce3207062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import itertools\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from snakemake.io import expand\n",
    "import pyranges as pr\n",
    "from pyfaidx import Fasta\n",
    "from mizani.formatters import percent_format\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "p = os.path.dirname(os.getcwd())\n",
    "sys.path.append(p)\n",
    "\n",
    "from scripts.utils import *\n",
    "from scripts.vcf_utils import *\n",
    "from scripts.plotting import *\n",
    "\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21122dd2-9893-4b05-b6f3-27925ac73a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_theme(base_size=11, w=4, h=3):\n",
    "    \"\"\"\n",
    "    Custom plotnine theme with:\n",
    "    - White background\n",
    "    - Clean styling\n",
    "    - Axes and ticks retained\n",
    "\n",
    "    Parameters:\n",
    "    - base_size: Base font size\n",
    "\n",
    "    Returns:\n",
    "    - plotnine.theme object\n",
    "    \"\"\"\n",
    "    return (\n",
    "        theme_minimal(base_size=base_size)\n",
    "        + theme(\n",
    "            # White background\n",
    "            panel_background=element_rect(fill='white', color=None),\n",
    "            plot_background=element_rect(fill='white', color=None),\n",
    "\n",
    "            # Remove grid lines\n",
    "            panel_grid_major=element_blank(),\n",
    "            panel_grid_minor=element_blank(),\n",
    "            panel_border=element_blank(),\n",
    "\n",
    "            # Keep axis lines & ticks (don't blank them)\n",
    "            axis_line=element_line(color='black'),\n",
    "            axis_ticks=element_line(color='black'),\n",
    "\n",
    "            plot_title=element_text(hjust=0.5, family='Helvetica'),\n",
    "            axis_title_x=element_text(hjust=0.5, family='Helvetica'),\n",
    "            axis_title_y=element_text(hjust=0.5, margin={'t':0, 'r':-2, 'b':0, 'l':0}, family='Helvetica'),\n",
    "            \n",
    "            # Styling text\n",
    "            legend_title=element_blank(),\n",
    "            axis_title=element_text(size=base_size + 1, family='Helvetica'),\n",
    "            legend_text=element_text(size=base_size-2, family='Helvetica'),\n",
    "            axis_text=element_text(size=base_size, color='black', family='Helvetica'),\n",
    "            strip_text_x=element_text(size=base_size-1),\n",
    "            strip_text_y=element_text(size=base_size-1),\n",
    "            figure_size=(w, h),  # Controls plot dimensions (width x height in inches)\n",
    "            plot_margin=0.05      # Shrinks surrounding white space\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b16e749-9f7d-4632-93f6-b125a6354742",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config()\n",
    "od = '../'\n",
    "\n",
    "def proc_cfg(entry, od):\n",
    "    entry = entry.replace('../../', '')\n",
    "    entry = od+entry\n",
    "    return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e744b6d-e5e7-4eee-b6f0-4dc40cd94bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_meta()\n",
    "df = df.loc[~df['sample'].str.contains('_')]\n",
    "df['lab_sample'] = df['lab_number_sample'].astype(str)+'_'+\\\n",
    "                      df['lab_sampleid'].astype(str)+'_'+\\\n",
    "                      df['cell_line_id'].astype(str)\n",
    "df.columns\n",
    "df = df[['cell_line_id', 'sample', 'hapmap_DNA_ID',\n",
    "          'map_reads_assemblymap','lab_sample', 'population']].drop_duplicates()\n",
    "\n",
    "temp_df = pd.read_csv('../snakemake/transcript_discovery_personal/cell_line_ids.txt', header=None, names=['cell_line_id'])\n",
    "\n",
    "# make a 1000g cell line id col\n",
    "df['cell_line_id_1000g'] = df.cell_line_id\n",
    "\n",
    "inds = df.loc[~df.cell_line_id_1000g.isin(temp_df.cell_line_id.tolist())].index\n",
    "df.loc[inds, 'cell_line_id_1000g'] = df.loc[inds, 'hapmap_DNA_ID']\n",
    "len(df.index)\n",
    "\n",
    "# limit to just those in 1000g\n",
    "df = df.loc[df.cell_line_id_1000g.isin(temp_df.cell_line_id.tolist())]\n",
    "assert len(df.index) == 30\n",
    "\n",
    "# TODO bad sample that hasn't finished on espresso\n",
    "# bad_samples = ['NA19328']\n",
    "# df = df.loc[~df.cell_line_id_1000g.isin(bad_samples)]\n",
    "\n",
    "hap = ['hap1', 'hap2']\n",
    "\n",
    "meta_df = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3515176a-9440-48b8-93b0-ea8a83c8612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = proc_cfg(config['lr']['td_personal']['cerb']['ic_summary'],od)\n",
    "df = pd.read_csv(file)\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df['detected'] = True\n",
    "\n",
    "df['n_ic'] = df.groupby('cell_line_id')['ic_id'].transform('nunique')         \n",
    "df = df[['n_ic', 'cell_line_id']].drop_duplicates()\n",
    "\n",
    "assert len(df.index) == 30\n",
    "df = df.sort_values(by='n_ic', ascending=False)\n",
    "cell_line_order = df.cell_line_id.tolist()\n",
    "# cell_line_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e3ae24c-cd3a-489d-ab51-d39766dc4b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_ic_summary(meta_df, \n",
    "#                        nov='all',\n",
    "#                        genome='hg38',\n",
    "#                        order=None):\n",
    "#     \"\"\"\n",
    "#     Paramters:\n",
    "#         nov (str): Novelty of reported ICs {'all', 'nov'}\n",
    "#         genome (str): Genome for detection of ICs {'hg38', 'pers'}\n",
    "#     Returns:\n",
    "#         temp (pandas DataFrame): ??\n",
    "#         big_df (pandas DataFrame): Some sort of summary dataframe\n",
    "#         samples_2 (list of str): Cell line ids of 2 missing samples\n",
    "#         samples_28 (list of str): Cell line ids of 28 included samples\n",
    "#     \"\"\"\n",
    "\n",
    "#     file = proc_cfg(config['lr']['td_personal']['cerb']['ic_summary'],od)\n",
    "#     df = pd.read_csv(file)\n",
    "#     df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "#     df['detected'] = True\n",
    "    \n",
    "#     # 1.5 only novel ics and count per cell line\n",
    "#     if nov == 'nov':\n",
    "#         print(len(df.index))\n",
    "#         temp = df.loc[(df.structural_category!='full-splice_match')&\\\n",
    "#                       (df.structural_category!='incomplete-splice_match')]\n",
    "#         print(len(temp.index))\n",
    "#     elif nov == 'all':\n",
    "#         temp = df.copy(deep=True)\n",
    "    \n",
    "#     # get only the detection from mapping\n",
    "#     temp = temp[['ic_id', 'cell_line_id', 'map_genome', 'detected']]\n",
    "#     temp = temp.drop_duplicates()\n",
    "#     temp = temp.pivot(index=['ic_id', 'cell_line_id'], \n",
    "#                     columns=['map_genome'],\n",
    "#                     values=['detected'])\n",
    "    \n",
    "#     # flatten\n",
    "#     temp.columns = temp.columns.get_level_values(1)\n",
    "#     temp.columns.name = None\n",
    "    \n",
    "#     # reset index to make it a flat DataFrame\n",
    "#     temp = temp.reset_index()\n",
    "    \n",
    "#     # fill missing values with False\n",
    "#     temp = temp.fillna(False)\n",
    "\n",
    "    \n",
    "#     if genome == 'pers':\n",
    "#         # 1.75. get those that are detected in hap1/2 \n",
    "#         temp = temp.loc[(temp.hap1+temp.hap2)>0]\n",
    "#     elif genome == 'hg38': \n",
    "#         temp = temp.loc[(temp.hg38)==1]\n",
    "\n",
    "#     temp['n_ic'] = temp.groupby('cell_line_id')['ic_id'].transform('nunique')         \n",
    "#     temp2 = temp[['cell_line_id', 'n_ic']]\n",
    "\n",
    "#     # order by # of detected ICs if no explicit order is given, otherwise\n",
    "#     # order by the given order\n",
    "#     if not order:\n",
    "#         temp2 = temp2.sort_values(by='n_ic', ascending=False)\n",
    "#     else:\n",
    "#         temp2['cell_line_id'] = pd.Categorical(temp2['cell_line_id'], categories=order, ordered=True)\n",
    "#         temp2 = temp2.sort_values('cell_line_id')\n",
    "    \n",
    "#     temp2.drop_duplicates(inplace=True)\n",
    "#     # order = temp2.cell_line_id.tolist()\n",
    "#     temp.drop(['hap1', 'hap2', 'hg38', 'n_ic'], axis=1, inplace=True)\n",
    "    \n",
    "#     temp['detected'] = True\n",
    "#     temp = temp.pivot(index='ic_id', columns='cell_line_id')\n",
    "#     temp.columns.name = None\n",
    "#     temp.columns = temp.columns.get_level_values(1)\n",
    "#     temp.fillna(False, inplace=True)\n",
    "    \n",
    "#     temp = temp[order]\n",
    "#     prev_ics = []\n",
    "#     big_df = pd.DataFrame()\n",
    "#     for i, c in enumerate(temp.columns):\n",
    "#         temp2 = temp.loc[temp[c]==True]\n",
    "#         pop = meta_df.loc[meta_df.cell_line_id_1000g==c, 'population'].values[0]\n",
    "#         ics = temp2.index.tolist()\n",
    "#         n = len(list(set(ics)-set(prev_ics)))\n",
    "#         prev_ics += ics\n",
    "#         # print(len(prev_ics))\n",
    "#         temp3 = pd.DataFrame(data=[[n,i,pop,c]], columns=['n_added_uniq', 'n_samples', 'population', 'cell_line_id_1000g'])\n",
    "#         big_df = pd.concat([big_df, temp3], axis=0)\n",
    "        \n",
    "#     big_df['genome'] = genome\n",
    "#     big_df['ic_nov'] = nov\n",
    "#     big_df['n_cumulative_ics'] = big_df.n_added_uniq.cumsum()\n",
    "\n",
    "#     samples_28 = order[:28]\n",
    "#     samples_2 = order[-2:]\n",
    "    \n",
    "#     return temp, big_df, samples_28, samples_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be15c9e1-620c-4fd8-a67b-506925696cd1",
   "metadata": {},
   "source": [
    "## All ICs, personal genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2c78cef-32f8-4e5b-bf42-6a8edbbba4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp, big_df, samples_28, samples_2 = process_ic_summary(meta_df, \n",
    "#                        nov='all',\n",
    "#                        genome='pers', \n",
    "#                        order=cell_line_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96a37c32-c2f0-4c6f-89fb-ca0448559212",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = proc_cfg(config['lr']['td_personal']['cerb']['ic_summary'],od)\n",
    "df = pd.read_csv(file)\n",
    "df['detected'] = True\n",
    "df = df.loc[df.sqanti_genome=='hg38']\n",
    "\n",
    "columns = ['sample_28_index',\n",
    "           'start_n_reads',\n",
    "           'n_ic_start', \n",
    "           'start_genome',\n",
    "           'n_ic_new',\n",
    "           'new_strat',\n",
    "           'wgs_sample_2_index',\n",
    "           'new_n_reads',\n",
    "           'ic_nov']\n",
    "\n",
    "df2 = pd.DataFrame()\n",
    "           \n",
    "def add_vals(df, vals, columns):\n",
    "    df2 = pd.DataFrame(data=[vals], columns=columns)\n",
    "    df = pd.concat([df, df2], axis=0)\n",
    "    return df\n",
    "\n",
    "# loop through each start genome\n",
    "for start_genome in ['hg38', 'pers']:\n",
    "\n",
    "    # loop through ic novelty\n",
    "    for nov in ['all', 'nov']:\n",
    "    \n",
    "        # loop through each combination\n",
    "        combinations = list(itertools.combinations(cell_line_order, 28))\n",
    "        for i, comb in enumerate(combinations):\n",
    "            \n",
    "            # reads 28 samples (starting reads)\n",
    "            n_reads = meta_df.loc[meta_df['cell_line_id_1000g'].isin(comb)]\n",
    "            assert len(n_reads.index) == 28\n",
    "            start_n_reads = n_reads['map_reads_assemblymap'].sum()\n",
    "        \n",
    "            # number of relevant ics found using LR-RNA-seq + GRCh38 \n",
    "            # for the starting 28 samples\n",
    "            if nov == 'all' and start_genome == 'hg38':\n",
    "                temp = df.loc[(df.map_genome=='hg38')&\\\n",
    "                              (df.cell_line_id.isin(comb))]\n",
    "            elif nov == 'nov' and start_genome == 'hg38':\n",
    "                 temp = df.loc[(df.map_genome=='hg38')&\\\n",
    "                               (df.cell_line_id.isin(comb))&\\\n",
    "                               (df.structural_category!='full-splice_match')&\\\n",
    "                               (df.structural_category!='incomplete-splice_match')]\n",
    "            elif nov == 'all' and start_genome == 'pers':\n",
    "                temp = df.loc[(df.map_genome.isin(['hap2', 'hap1']))&\\\n",
    "                              (df.cell_line_id.isin(comb))]\n",
    "            elif nov == 'nov' and start_genome == 'pers':\n",
    "                 temp = df.loc[(df.map_genome.isin(['hap2', 'hap1']))&\\\n",
    "                               (df.cell_line_id.isin(comb))&\\\n",
    "                               (df.structural_category!='full-splice_match')&\\\n",
    "                               (df.structural_category!='incomplete-splice_match')]\n",
    "            assert len(temp.cell_line_id.unique()) == 28\n",
    "            start_ics = temp.ic_id.unique()\n",
    "            n_start_ics = len(temp.ic_id.unique())\n",
    "                                        \n",
    "            # missing samples\n",
    "            samples_2 = list(set(cell_line_order)-set(comb))\n",
    "        \n",
    "            # reads 2 samples (# added reads)\n",
    "            n_reads = meta_df.loc[meta_df['cell_line_id_1000g'].isin(samples_2)]\n",
    "            assert len(n_reads.index) == 2\n",
    "            new_n_reads = n_reads['map_reads_assemblymap'].sum()\n",
    "        \n",
    "            # 1. adding 2 more samples by LR-RNA-seq only \n",
    "            # (ie only using GRCh38 as a reference)\n",
    "\n",
    "            if nov == 'all':\n",
    "                temp = df.loc[(df.map_genome=='hg38')&\\\n",
    "                              (df.cell_line_id.isin(samples_2))]\n",
    "            elif nov == 'nov':\n",
    "                temp = df.loc[(df.map_genome=='hg38')&\\\n",
    "                               (df.cell_line_id.isin(samples_2))&\\\n",
    "                               (df.structural_category!='full-splice_match')&\\\n",
    "                               (df.structural_category!='incomplete-splice_match')]\n",
    "            assert len(temp.cell_line_id.unique()) == 2\n",
    "            ics_2_rna = temp.ic_id.unique().tolist()\n",
    "            \n",
    "            vals = [i, start_n_reads,\n",
    "                    n_start_ics, start_genome, \n",
    "               len(list(set(ics_2_rna)-set(start_ics))), # increase in number, set difference\n",
    "               'rna_2_samples', np.nan, new_n_reads, nov]\n",
    "            df2 = add_vals(df2, vals, columns)\n",
    "        \n",
    "            # 2. adding 1 more sample by LR-RNA-seq + WGS\n",
    "            # (ie using personal GRCh38 only as reference)\n",
    "            for j, c_id in enumerate(samples_2):\n",
    "                # reads 1 sample1\n",
    "                n_reads = meta_df.loc[meta_df['cell_line_id_1000g'].isin([c_id])]\n",
    "                assert len(n_reads.index) == 1\n",
    "                new_n_reads = n_reads['map_reads_assemblymap'].sum()\n",
    "\n",
    "                if nov == 'all':\n",
    "                    temp = df.loc[(df.cell_line_id.isin([c_id]))&\\\n",
    "                                   (df.map_genome.isin(['hap2', 'hap1']))]\n",
    "                elif nov == 'nov':\n",
    "                    temp = df.loc[(df.cell_line_id.isin([c_id]))&\\\n",
    "                                  (df.map_genome.isin(['hap2', 'hap1']))&\\\n",
    "                                  (df.structural_category!='full-splice_match')&\\\n",
    "                                  (df.structural_category!='incomplete-splice_match')]\n",
    "                    \n",
    "                ics_1_wgs = temp.ic_id.unique().tolist()\n",
    "                vals = [i, start_n_reads,\n",
    "                        n_start_ics, start_genome, \n",
    "                   len(list(set(ics_1_wgs)-set(start_ics))), # increase in number, set difference\n",
    "                   'wgs_1_sample', j, new_n_reads, nov]\n",
    "                df2 = add_vals(df2, vals, columns)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60653f48-4786-48f4-9aff-490109c2032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('250714_28_sample_experiment.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b731d437-03ee-468a-982f-766575aa801c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5220"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df2[['sample_28_index', 'start_genome', 'ic_nov', 'wgs_sample_2_index']].drop_duplicates().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ac497c-8349-421f-9c8a-5811ae4dcec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fb24e7-47d8-49d4-ae9c-198118becc1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
