{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5de71228-a45b-404e-a23f-ae5a010dab34",
   "metadata": {},
   "source": [
    "## Goal: get SNPs both CLOSE to SJs (exonic, +- 10 bp) and within SSs themselves\n",
    "\n",
    "* 1. Use these to compute what % of novel SJs only in hap1/hap2 have a +- 10bp SNP OR SNP in the SS (should be very close to another I'm computing) AND\n",
    "* 2. Subset on just known SJs to compute a known SJ-proximal SNP density score that I can use to correlate against the % increase in ICs / SJs detected to predict how much novel splicing we're missing in populations / samples that we actually didn't profile here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe2a6747-ed87-420f-b26e-933e1bdb456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import swan_vis as swan\n",
    "import yaml\n",
    "from snakemake.io import expand\n",
    "import cerberus\n",
    "import pyranges as pr\n",
    "import upsetplot\n",
    "\n",
    "p = os.path.dirname(os.getcwd())\n",
    "sys.path.append(p)\n",
    "\n",
    "from scripts.utils import *\n",
    "from scripts.vcf_utils import *\n",
    "from scripts.plotting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "706a3d5a-501a-4e7b-8127-776200a50b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config()\n",
    "od = '../'\n",
    "\n",
    "def proc_cfg(entry, od):\n",
    "    entry = entry.replace('../../', '')\n",
    "    entry = od+entry\n",
    "    return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4803fe2b-03a2-4ea2-96cb-fdeeb4474135",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_meta()\n",
    "df = df.loc[~df['sample'].str.contains('_')]\n",
    "df['lab_sample'] = df['lab_number_sample'].astype(str)+'_'+\\\n",
    "                      df['lab_sampleid'].astype(str)+'_'+\\\n",
    "                      df['cell_line_id'].astype(str)\n",
    "df.columns\n",
    "df = df[['cell_line_id', 'sample', 'hapmap_DNA_ID',\n",
    "          'map_reads_assemblymap','lab_sample', 'population']].drop_duplicates()\n",
    "\n",
    "temp_df = pd.read_csv('../snakemake/transcript_discovery_personal/cell_line_ids.txt', header=None, names=['cell_line_id'])\n",
    "\n",
    "# make a 1000g cell line id col\n",
    "df['cell_line_id_1000g'] = df.cell_line_id\n",
    "\n",
    "inds = df.loc[~df.cell_line_id_1000g.isin(temp_df.cell_line_id.tolist())].index\n",
    "df.loc[inds, 'cell_line_id_1000g'] = df.loc[inds, 'hapmap_DNA_ID']\n",
    "len(df.index)\n",
    "\n",
    "# limit to just those in 1000g\n",
    "df = df.loc[df.cell_line_id_1000g.isin(temp_df.cell_line_id.tolist())]\n",
    "assert len(df.index) == 30\n",
    "\n",
    "# TODO bad sample that hasn't finished on espresso\n",
    "# bad_samples = ['NA19328']\n",
    "# df = df.loc[~df.cell_line_id_1000g.isin(bad_samples)]\n",
    "\n",
    "hap = ['hap1', 'hap2']\n",
    "\n",
    "meta_df = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3be258-20fa-4bb8-82e1-1c901a3250c0",
   "metadata": {},
   "source": [
    "## Dev for getting the +- 10 + SS bed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14fc5a81-1087-4a42-bc95-6fe9658cba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = proc_cfg(config['lr']['td_personal']['sqanti']['sj_summary'],od)\n",
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb7158cd-643b-4fa1-90cb-69e5451d1989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24934518\n",
      "8311506\n"
     ]
    }
   ],
   "source": [
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "# remove sqanti genome and drop dupes\n",
    "# the sqanti genome / sqanti metrics SHOULD be irrelevant here\n",
    "df = df.drop(['sqanti_genome', 'canonical', 'splice_motif'], axis=1)\n",
    "print(len(df.index))\n",
    "df = df.drop_duplicates()\n",
    "print(len(df.index))\n",
    "\n",
    "# then make sure that there are no dupe. sj+sj nov+sample+map genome\n",
    "temp = df.loc[df[['sj_id', 'junction_novelty',\n",
    "                  'cell_line_id', 'map_genome', 'start_site_novelty',\n",
    "                  'end_site_category']].duplicated(keep=False)]\n",
    "assert len(temp.index) == 0\n",
    "del temp\n",
    "\n",
    "df.rename({'end_site_category': 'end_site_novelty'}, axis=1, inplace=True)\n",
    "\n",
    "# transform to be t/f for each ic per genome\n",
    "temp = pd.crosstab(index=[df.sj_id, df.junction_novelty,\n",
    "                                 df.start_site_novelty,\n",
    "                                 df.end_site_novelty, df.cell_line_id],\n",
    "                          columns=df.map_genome,\n",
    "                          values=df.map_genome,\n",
    "                          aggfunc=lambda x: True).fillna(False).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59bbc28-d15a-4c1c-adce-01e5070e5032",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_back = temp.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e51fbd50-7b27-4910-97af-7b1c722646f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp = temp_back.copy(deep=True)\n",
    "# check w/ just 1 genome + cell line at first so I can \n",
    "# dl GTF and check it\n",
    "temp = temp.loc[(temp.cell_line_id=='HG03732')&\\\n",
    "                (temp.hap1==True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a884cda5-e197-4b65-8f79-8526c39ba02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp[['Chromosome', 'Strand', 'Start', 'End']] = temp.sj_id.str.split('_', expand=True)\n",
    "temp = temp[['Chromosome', 'Strand', 'Start', 'End',\n",
    "             'cell_line_id', 'sj_id']].drop_duplicates()\n",
    "\n",
    "temp.Start = temp.Start.astype(int)\n",
    "temp.End = temp.End.astype(int)\n",
    "assert len(temp.loc[temp.Start>temp.End])==0\n",
    "\n",
    "# melt to 5' and 3'\n",
    "temp = temp.melt(id_vars=['Chromosome', 'Strand', 'cell_line_id', 'sj_id'],\n",
    "                 value_vars=['Start', 'End'])\n",
    "temp['sj_loc'] = ''\n",
    "temp.loc[temp.map_genome=='Start', 'sj_loc'] = 'start'\n",
    "temp.loc[temp.map_genome=='End', 'sj_loc'] = 'end'\n",
    "\n",
    "temp.rename({'value':'Start'}, axis=1, inplace=True)\n",
    "# need to verify that this is working using like one motif or something make\n",
    "# sure I don't have off-by-one errors\n",
    "# verified\n",
    "temp['Start'] = temp.Start-2\n",
    "temp['End'] = temp.Start+1\n",
    "\n",
    "# add 10 to start, rm 10 from end\n",
    "# verified https://trello.com/c/qzMAZpAm\n",
    "temp.loc[temp.sj_loc=='start', 'Start'] = temp.loc[temp.sj_loc=='start', 'Start']-9\n",
    "temp.loc[temp.sj_loc=='start', 'End'] = temp.loc[temp.sj_loc=='start', 'End']+2\n",
    "\n",
    "\n",
    "temp.loc[temp.sj_loc=='end', 'End'] = temp.loc[temp.sj_loc=='end', 'End']+14\n",
    "temp.loc[temp.sj_loc=='end', 'Start'] = temp.loc[temp.sj_loc=='end', 'Start']+2\n",
    "\n",
    "temp.drop(['cell_line_id', 'map_genome'], axis=1, inplace=True)\n",
    "\n",
    "temp = pr.PyRanges(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0df0dcb8-62a3-455d-a6cd-75ffdcb9661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.to_bed('test_3.bed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ceb679-6a3e-4868-8820-3947d2f15172",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
